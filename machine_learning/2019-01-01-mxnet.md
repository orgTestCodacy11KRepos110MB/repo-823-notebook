---
layout: post
title: MXNet 体系结构
---


本文是软件体系结构大作业，作业要求是分析开源软件的体系结构。本文是对 MXNet 的分析，把内容放到这里，说不定什么时候会有用。

- *
{:toc}


## 1. 简介

MXNet 是支持多种语言的机器学习库，用它能够快速地实现机器学习算法，也能很容易地部署到不同的平台上。它后端使用 C++ 编写，确保高效，前端提供了对 Python、C++、Scala、R 等语言的支持，以保证灵活性。

### 1.1 MXNet 的特点

- 灵活的编程模型: 支持命令式（ imperative）、声明式（symbolic）网络创建方式
- 支持多种设备：支持 CPU 和 GPU、支持云端的 GPU 实例、支持移动小型设备
- 多语言支持: C++, Python, R, Scala, Julia, Matlab, Javascript
- 支持分布式计算: 支持多 CPU/GPU 节点的计算

![text=深度学习框架](https://wangyu-name.oss-cn-hangzhou.aliyuncs.com/superbed/2019/05/28/5ced03e4451253d17802314b.jpg)


目前深度学习库有很多，图 1 列举了部分，下表对比了 MXNet 和其他流行的深度库的特点。

|-|主语言|从语言|硬件|分布式|命令式|声明式|
|:----|:----|:--|:----|:----|:----|:--|
|Caffe|C++|Python/Matlab|CPU/GPU|x|x|v|
|Torch|Lua|-|CPU/GPU/FPGA|x|v|x|
|Theano|Python|-|CPU/GPU|x|x|v|
|TensorFlow|C++|Python|CPU/GPU/Mobile|v|x|v|
|MXNet|C++|Python/R/Julia/Go|CPU/GPU/Mobile|v|v|v|

表来自：_MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems_


### 1.2 主要功能

在用户层面 MXNet 提供了如下功能：

- 高效的数学运算，主要有 NDArray 支持，提供类似 numpy 的数学运算功能
- 完善的符号定义，便于用户定义满足任意需求的运算图
- 对数学运算自动求导
- 提供用于计算机视觉的图片处理工具，以便于做 image augmentation
- IO 接口，便于高效地在 CPU - GPU 之间传输数据以及对训练过程中的数据进行预处理
- 用于机器学习的各种工具，如不同的评价指标、优化器、损失函数等
- Gluon API，对各种神经网络结构（CNN, RNN 等）进行了抽象，提供高层 API 方便用户搭建神经网络模型

### 1.3 代码行数

代码行数使用 [cloc](https://github.com/AlDanial/cloc) 统计。

```
-------------------------------------------------------------------------------
Language                     files          blank        comment           code
-------------------------------------------------------------------------------
Python                         684          22676          46012         101931
C/C++ Header                   316           9241          22120          80301
C++                            275           8507          10739          61784
Markdown                       390          14431              0          44910
Perl                           108           5319           6917          28685
Scala                          196           4071           9058          21381
CUDA                           153           2707           6038          18677
Clojure                        129           1638           2550          10416
Julia                           83           2394           2038           9626
Bourne Shell                   216           1678           4420           6567
Java                            65            921           1460           3627
R                               24            447            594           2390
CSS                              2            474             94           2385
SWIG                             4            208           1610           2285
make                            48           1309           2952           2262
Maven                           17             85            282           2097
JavaScript                      12            258            461           1810
CMake                           19            315            485           1794
Protocol Buffers                 2            346           1345           1663
Jupyter Notebook                18              0           9620           1611
Groovy                           2            146            103           1487
JSON                             8              0              0           1196
Smalltalk                       41            135              0            978
MATLAB                           6            116            326            724
SVG                              5              0             77            513
HTML                             6             39             18            474
YAML                            14             78            192            410
DOS Batch                        5            117             81            399
Cython                           3             70             63            267
XML                              5             32             97            254
INI                              1             18              0            137
Gradle                           2             27             17            127
PowerShell                       6             34            112            106
Lisp                             1             12              0             63
Dockerfile                       2             18             53             57
reStructuredText                 1             16             14             31
ANTLR Grammar                    1             22             22             30
TOML                             2              5              0             28
-------------------------------------------------------------------------------
SUM:                          2872          77910         129970         413483
-------------------------------------------------------------------------------
```

### 1.4 项目中包和类的数量

#### 1.4.1 mxnet C++ 核心代码

MXNet 的 C++ 代码分两部分，第一部分为实现 MXNet 的后端代码，另外一部分为 MXNet 用于深度学习的 C++ 接口。

mxnet C++ 核心代码提供了 mxnet 的各项基础设施，头文件在 `/include` 中，具体实现在 `/src` 中。这部分涉及到 22 个模块，下面是对个别模块的描述。

|文件|描述 |
|:--|:----|
|base.h |	|
| c_api.h | mxnet 的 C API |
| c_api_error.h |	Error handling for C API |
| c_api_test.h |	C API of mxnet for ease of testing backend in Python |
| c_predict_api.h |	C predict API of mxnet, contains a minimum API to run prediction. This file is self-contained, and do not dependent on any other files |
| engine.h |	Engine that schedules all the operations according to dependency |
| executor.h |	 |
| graph_attr_types.h |	Data structures that can appear in graph attributes |
| imperative.h |	 |
| io.h |	 |
| kvstore.h |	 |
| libinfo.h |	Get features of the MXNet library at runtime |
| ndarray.h |	 |
| op_attr_types.h |	Additional operator attributes beside the ones provided by NNVM |
| operator.h |	 |
| operator_util.h |	Utility functions and registries to help quickly build new operators. [Deprecated] Use the register functions in this file when possible to simplify operator creations. Operators registered in this file will be exposed to both NDArray API and symbolic API |
| random_generator.h |	Parallel random number generator |
| resource.h |	Global resource allocation handling |
| rtc.h |	 |
| storage.h |	Storage manager across multiple devices |
| tensor_blob.h |	TBlob class that holds common representation of arbirary dimension tensor, can be used to transformed to normal fixed dimenson tensor |
| tuple.h |	Data structure Tuple and TShape to store dynamic sized shapes |

表中数据来自 [[5]](https://mxnet.incubator.apache.org/versions/master/doxygen/files.html)

这部分一共包 55 个类公开暴露的类。在具体实现中共牵扯到 1006 个类。

#### 1.4.2 MXNet 用于深度学习的 C++ 接口

mxnet 的 C++ 接口封装了深度学习所需要的最基础的设施，C++ 接口不单单用于开发人员使用 C++ 直接编写深度学习模型，还支持了其他语言，如 Python 的调用。

这部分包含 19 个模块，个别模块描述如下：

|文件|描述 |
|:--|:----|
|base.h | 	|
|executor.h | 	|
|initializer.h | 	Random initializer|
|io.h | 	|
|kvstore.h | 	|
|lr_scheduler.h | 	Scheduling learning rate|
|metric.h | 	|
|model.h | 	MXNET.cpp model module|
|monitor.h | 	Monitor definition|
|MxNetCpp.h | 	Meta include file for mxnet.cpp|
|ndarray.h | 	|
|op.h | 	Definition of all the operators|
|op_map.h | 	Definition of OpMap|
|op_suppl.h | 	A supplement and amendment of the operators from op.h|
|op_util.h | 	Operator helper functions|
|operator.h | 	|
|optimizer.h | 	Definition of optimizer|
|shape.h | 	Definition of shape|
|symbol.h | 	Definition of symbol|

表中数据来自 [[5]](https://mxnet.incubator.apache.org/versions/master/doxygen/files.html)

一共有 47 个类。这些类都直接暴露给用 C++ 开发深度学习的开发者。

#### 1.4.3 Python 接口部分

```sh
.
├── attribute.py
├── autograd.py
├── base.py
├── callback.py
├── context.py
├── contrib
├── _ctypes
├── _cy2
├── _cy3
├── cython
├── engine.py
├── executor_manager.py
├── executor.py
├── gluon
├── image
├── initializer.py
├── __init__.py
├── io
├── kvstore.py
├── kvstore_server.py
├── libinfo.py
├── log.py
├── lr_scheduler.py
├── metric.py
├── misc.py
├── model.py
├── module
├── monitor.py
├── name.py
├── ndarray
├── ndarray_doc.py
├── notebook
├── operator.py
├── optimizer
├── profiler.py
├── random.py
├── recordio.py
├── registry.py
├── rnn
├── rtc.py
├── runtime.py
├── symbol
├── symbol_doc.py
├── test_utils.py
├── torch.py
├── util.py
└── visualization.py
```

共有 50 个模块，含 386 个类。

## 2. 功能需求

如今，数据集越来越大，计算的需求也越来越多。随着GPU和集群对加速神经网络训练的发展，需要在传统机器学习的代码中进行调整使其利用GPU和集群的资源优势。这就需要根据可用的GPU来扩大计算的规模，需要明确每一个数据结构都被保存在何处，需要能自动处理曾经阻碍神经网络研究的导数计算。需要对多种语言的支持，对多种语言的支持保证了其灵活性。需要提供图片处理工具，用于计算机视觉的处理。[[8]](https://mxnet.apache.org/versions/master/faq/why_mxnet.html#deep-nets-on-fast-computers)



## 3. 质量属性场景

### 3.1 易用性

对于广大机器学习从业者、学者，深度学习库应该能够让他们快速上手，将注意力更多地放在算法的设计和功能的实现上。MXNet 应该具备易用性的质量属性。

|场景部分 | 可能的值|
|:--------|:---------|
|刺激源 | MXNet 的潜在用户 |
|刺激 | 让用户能够快速上手，并灵活高效地开发深度学习系统 |
|制品 | MXNet 的 API 设计 |
|环境 | 当用户准备使用 MXNet 时 |
|响应 | API 清晰明确，用户能够轻松上手 |
|响应度量  | 有深度学习基础且有编程经验者，能够在半小时内掌握基本用法 |

### 3.2 高效性

深度学习算法往往需要大量的计算，尽管有 GPU 来辅助计算，但很多时候依然需要花费数小时、数天来训练模型。因此深度学习库的高效性非常重要，高效的库能够更快地运行算法，开发者能够对系统进行快速迭代。另外，高效的计算也能减少对电力的消耗，既节约资源又环保。

|场景部分 | 可能的值|
|:--------|:---------|
|刺激源 | MXNet 的使用者 |
|刺激 | 用户希望深度学习库能够高效地执行 |
|制品 | MXNet 的 架构与算法设计 |
|环境 | 当用户使用 MXNet 时 |
|响应 | MXNet 能够高效地完成算法 |
|响应度量  | 至少不比同类工具慢 |

### 3.3 可靠性

深度学习算法往往需要花费数小时甚至数天来训练模型，而如果系统出现故障，整个训练过程都需要重新来过，因此 MXNet 的长时间无故障运行能力尤其重要。

|场景部分 | 可能的值|
|:--------|:---------|
|刺激源 | MXNet 的使用者 |
|刺激 | 算法被执行时 |
|制品 | mxnet 整个系统  |
|环境 | 当用户正常执行算法时 |
|响应 | MXNet 保持长时间无故障的运行 |
|响应度量  | 无内存泄露，无未捕获异常 |

### 3.4 可维护性

深度学习当前的发展十分迅速，随着新论文的发表，新的深度学习模型和方法需要被添加进 MXNet 框架中。所以当 MXNet 产生 BUG ，或随着新技术的产生，而需要新增功能时， MXNet 的开发者需要对其进行定位维修。

|场景部分 | 可能的值|
|:--------|:---------|
|刺激源 | MXNet 的开发者 |
|刺激 | MXNet 产生 BUG 或需要新增功能 |
|制品 | MXNet 的新功能以及 BUG 的消除 |
|环境 | 当新技术或功能需要被添加时 |
|响应 | 开发人员迅速找到维修点定位维修，且代价尽可能低 |
|响应度量  | 能在新功能或 BUG 出现后的24小时内进行维护 |

### 3.5 可测试性

当新的功能或新的模块被开发出来后，需要经过测试来验证功能或模块的正确与否。 MXNet 需要易于通过测试揭示功能或模块的缺陷。

|场景部分 | 可能的值|
|:--------|:---------|
|刺激源 | MXNet 的开发人员，增量开发人员 |
|刺激 | 执行新模块的测试 |
|制品 | MXNet 的模块 |
|环境 | 新模块完成时 |
|响应 | 模块具有控制行为的接口，并且输出可以被观察 |
|响应度量  | 测试用例无误 |

### 3.6 可移植性

因为深度学习模型需要在很多不同的的地方运行：从笔记本电脑和能通过大型网络互联和大量的计算能力服务器群，到通常是连接相距甚远设备的移动通讯工具。

|场景部分 | 可能的值|
|:--------|:---------|
|刺激源 | MXNet 的使用者 |
|刺激 | 当在不同的介质中运行MXNet时 |
|制品 | MXNet 的完整代码 |
|环境 | 跨系统和平台 |
|响应 | 代码的核心功能连同所有依赖打包成C++源文件 |
|响应度量  | 不存在平台兼容性问题 |

### 3.7 可重用性

|场景部分 | 可能的值|
|:--------|:---------|
|刺激源 | 机器学习相关从业者、研究人员、学生 |
|刺激 | 让用户能够快速上手，并灵活高效地开发深度学习系统 |
|制品 | MXNet 的 API 设计 |
|环境 | 当用户准备使用 MXNet 时 |
|响应 | API 清晰明确，用户能够轻松上手 |
|响应度量  | 有深度学习基础且有编程经验者，能够在半小时内掌握基本用法 |

## 4. 软件体系结构设计

### 4.1 MXNet 的整体设计

MXNet 后端使用 C++ 编写，确保高效，前端提供多种语言支持，保证灵活性。

![](https://wangyu-name.oss-cn-hangzhou.aliyuncs.com/superbed/2019/05/29/5cee1c2b451253d178166ea9.jpg)

图片来自 [[7]](https://raw.githubusercontent.com/cyrusmvahid/GluonBootcamp/master/slides/MXNet%20Overview.pptx)

MXNet 的代码库中主要目录如下：

```sh
.
├── 3rdparty      - 第三方依赖项，使用 git submodule 引入
├── amalgamation  - 用于 mxnet 打包, 以方便在客户端调用
├── ci            - 持续集成相关的脚本
├── cmake         - 用于构建的 cmake 脚本
├── contrib       - 开源社区贡献的组件
├── cpp-package   - C++ 安装包
├── docker        - 用于构建 mxnet 的 docker 镜像. 
├── docs          - 从代码自动生成的文档
├── example       - 包含了各种例子
├── include/mxnet - 包含 .h 文件，mxnet 库的 C++ API
├── julia         - julia 的接口
├── make          - makefile 脚本
├── matlab        - matlab 接口
├── plugin        - 一些第三方插件
├── python        - mxnet 的 Python 接口
├── src           - mxnet 的 C++ 源文件
```

### 4.2 MXNet 的后端结构

MXNet 的后端核心组成

![](https://wangyu-name.oss-cn-hangzhou.aliyuncs.com/superbed/2019/05/29/5cede6cf451253d1780d1f73.jpg)

图片来自于 [[1]](https://mxnet.incubator.apache.org/versions/master/architecture/index.html)

- Runtime Dependency Engine: 根据读写依赖关系调度和执行运算。
- Storage Allocator: 高效地在 GPU 或 CPU 上分配和回收内存。
- Resource Manager: 管理全局资源，比如随机数发生器。
- NDArray: 动态、异步的多维数组，提供高可扩展性的命令式编程。
- Symbolic Execution: 静态符号图执行器，高效地执行和优化符号图。
- Operator: 定义静态地前向和后续运行（反向传播）。
- Symbol Construction: 符号构造，提供一个构造运算图的方法。
- KVStore: Key-value 存储接口，用于高效地参数同步。
- Data Loading(IO):  用于高效你数据加载。


对应到代码中牵扯到到下面这些头文件：

```sh
include/mxnet/
├── base.h
├── c_api_error.h
├── c_api.h
├── c_api_test.h
├── c_predict_api.h
├── engine.h
├── executor.h
├── graph_attr_types.h
├── imperative.h
├── io.h
├── kvstore.h
├── libinfo.h
├── ndarray.h
├── op_attr_types.h
├── operator.h
├── operator_util.h
├── random_generator.h
├── resource.h
├── rtc.h
├── storage.h
├── tensor_blob.h
└── tuple.h
```

具体的实现放在 `/src` 目录下：

```sh
./src/
├── c_api
├── common
├── engine
├── executor
├── imperative
├── io
├── kvstore
├── ndarray
├── nnvm
├── operator
├── optimizer
├── profiler
└── storage
```

#### 4.2.1 base

在 `base.h` 中引入了两个类，上下文信息类 Context，实际执行时的上下文类 RunContext。

```c++
struct Context {
    DeviceType dev_type;
    int32_t dev_id;
    inline void Save(dmlc::Stream *strm) const {...}; //将Context信息记入二进制流
    inline bool Load(dmlc::Stream *strm) {...}; //从二进制流中载入Context信息
    inline static Context Create(DeviceType dev_type, int32_t dev_id = -1); //构造一个新的Context
    inline static Context CPU(int32_t dev_id = 0);
    inline static Context GPU(int32_t dev_id=-1);
    inline static int32_t GetGPUCount();
    inline static void GetGPUMemoryInformation(int dev, int *free, int *total);
    inline static Context CPUPinned(int32_t dev_id = -1);
    inline static Context CPUShared(int32_t dev_id = 0);
    inline static Context FromString(const std::string& str);
};
```

```c++
struct RunContext {
    Context ctx;
    void *stream;
    //...
};
```

#### 4.2.2 Execution Engine

执行引擎用于并行化计算过程，根据函数的依赖关系来合理地调度并执行函数。有依赖关系的两个函数，需要顺序执行，彼此没有依赖关系的函数，可以并行执行。根据加入执行引擎的函数的信息依赖，计算过程可以表示为一个有向无环图。使用相应的图算法（如拓扑排序）可以规划出图的计算顺序。函数的执行会交给线程池中不同线程来执行，以此实现并行计算。

Engine 负责高效地执行任务，它支持同步和异步两种方式，同步执行时，提交给 Engine 任务后会当前线程会阻塞至任务完成。异步执行时，指令会立即返回，但具体的操作会加入到执行引擎中，后在后端执行。异步执行，能极大地增强并行程度。

![](https://wangyu-name.oss-cn-hangzhou.aliyuncs.com/superbed/2019/05/29/5cede9d1451253d1780d74be.jpg)

图片来自 [[7]](https://raw.githubusercontent.com/cyrusmvahid/GluonBootcamp/master/slides/MXNet%20Overview.pptx)

Engine 的接口定义在 `include\mxnet\engine.h` 中，其中包含下面一些类：

```
class Engine  - 负责根据图的节点的依赖关系，并行运算
class CallbackOnComplete  - 用于异步调用结束时调用的回调函数
struct Var    - 用于包含函数的依赖信息
struct Opr    - 用于表示各种运算
enum class FnProperty  - 函数类型枚举类
```

`CallbackOnComplete` 用于异步函数在运行结束时调用的回调函数类，它通过对 `()` 进行重载，用类对回调函数进行了一层封装：

```c++
class CallbackOnComplete {
  public:
    inline void operator()() const {
        (*callback_)(engine_, param_);
    }
  private:
    friend class ::mxnet::Engine;
    void (*callback_)(Engine *, void *);
    Engine* engine_;
    void* param_;
};
```

枚举类 `FnProperty` 列出了常用的函数类型：

```c++
enum class FnProperty {
    kNormal, // 一般操作
    kCopyFromGPU, // 从GPU上拷贝内容到其它设备的操作
    kCopyToGPU, // 从其它设备向GPU拷贝内容的操作
    kCPUPrioritized, // CPU上优先选择的同步操作
    kAsync, // 异步函数调用
    kDeleteVar, // 用来删除变量的函数
    kGPUPrioritized, // GPU上优先选择的同步操作
};
```

engine 是对操作进行调度执行的引擎，`Engine` 类的定义如下：

```c++
class Engine {
  public:
    //停止引擎中的所有worker
    virtual void Stop() {}
    //启动引擎中的所有worker
    virtual void Start() {}
    //将一个操作加入引擎
    virtual void Push(...);
    //将一个异步操作加入引擎
    virtual void PushAsync(...);
    //将一个同步操作加入引擎
    virtual void PushSync(...);
    // 用来生成OnComplete回调的工厂函数
    inline CallbackOnComplete CreateCallback(...);
};
```



#### 4.2.3 executor

静态符号图执行器，用于高效地执行和优化符号图。

```c++
class Executor {
  public:
    virtual void Forward(bool is_train) = 0;
    virtual void PartialForward(bool is_train, int step, int *step_left) = 0;
    virtual void Backward(const std::vector &head_grads, bool is_train = true) = 0;
};
```

#### 4.2.4 operator

相关源文件为 `include\mxnet\operator.h` 和 `src\operator\`。Operator 定义了 MXNet 计算图中基础的操作单位。在 Operator 中分别使用Forward和Backward两个函数实现了前向和后向运算。

```c++
class Operator {
  public:
    // 进行前向计算，将计算结果保存在 out_data 中
    virtual void Forward(const OpContext &ctx,
                         const std::vector<TBlob> &in_data,
                         const std::vector<OpReqType> &req,
                         const std::vector<TBlob> &out_data,
                         const std::vector<TBlob> &aux_states) = 0;
    
    // 后向计算，将梯度写入 in_grad
    virtual void Backward(const OpContext &ctx,
                          const std::vector<TBlob> &out_grad,
                          const std::vector<TBlob> &in_data,
                          const std::vector<TBlob> &out_data,
                          const std::vector<OpReqType> &req,
                          const std::vector<TBlob> &in_grad,
                          const std::vector<TBlob> &aux_states);
};
```


在 Operator 中仅包含了操作计算的接口，操作的具体信息保存在 OperatorProperty 类中，它负责保存所有与 Operator 有关的信息。且能根据运行环境产生适用于不同设备（GPU、CPU 等）的 Operator。同时，它还为计算引擎提供了一些可以优化操作计算的函数。

```c++
class OperatorProperty {
  public:
    //初始化 Operator 时需要用到的参数
    virtual void Init(const std::vector<std::pair<std::string, std::string>>& kwargs) = 0;
    
    //获取为 Operator 准备的参数
    virtual std::map<std::string, std::string> GetParams() const = 0;
    
    virtual int NumOutputs() const {...}
    
    virtual bool InferShape(std::vector<TShape> *in_shape,
        std::vector<TShape> *out_shape, std::vector<TShape> *aux_shape) const = 0;
    
    //进行 Operator 的类型推断
    virtual bool InferType(...);
    
    //构建Operator
    virtual Operator* CreateOperator(Context ctx) const = 0;
};
```

要想创建更多的操作，只需要继承 `OperatorProperty` 类，并实现 `Forward` 和 `Backward` 方法即可。

#### 4.2.5 storage

Storage 是一个跨平台的内存管理类，它提供了内存分配和回收的功能，真正的内存指针分配在 Storage 类内部的Handle结构体中：

```c++
struct Handle {
    void * dptr{nullptr}; //内存地址
    size_t size{0};
    Context ctx;
    int shared_pid{-1};
    int shared_id{-1};
};

class Storage {
  public:
    Handle Alloc(size_t size, Context ctx) {...};
    virtual void Alloc(Handle* handle) = 0;
    virtual void Free(Handle handle) = 0;
};
```

#### 4.2.6 ndarray

ndarray 是 mxnet 中的核心数据结构，和 numpy 类似提供多维数组的抽象。部分 ndarray 包含实际数据，另一些只是其他 ndarray 的视图。比如在 Python 中对 ndarray 使用了切片操作，就会产生视图。在 mxnet 中，ndarray 是使用 Chunk 类来完成数据存储的，在 NDArray 类中记录了 Chunk 实例的指针，并记录了数据偏移量，dtype 等信息。这样的设计可以让最大程度地节约存储，且提高数据处理的效率。在前端代码中，多个 ndarry 可以共享同一片存储，而且多个 ndarray 可以有不同的数据类型。

```c++
class NDArray {
    std::shared_ptr<Chunk> ptr_{nullptr};
    TShape shape_;
    size_t byte_offset_ = 0;
    int dtype_ = -1;
    bool reuse_ = false;
    nnvm::NodeEntry entry_;
    mutable TBlob tblob_;
};
```

Chunk 是作为 Ndarray 和 Storage 之间的一层抽象，Chunk 中保存了 Storage 的指针，并包含一些额外分辅助信息。Ndarray 提供了多维数组的抽象，但它底层的实现有可能是稠密的也可以是稀疏的，存储的位置等信息 ndarray 都是不关注的。这些都由 Chunk 类来负责管理。

```c++
struct Chunk {
    // 数据本身
    Storage::Handle shandle;
    
    // 辅助数据，主要用于存储稀疏数据时，数据本身在 shandle 中，索引在 aux_data 中。
    std::vector<Storage::Handle> aux_handles;
    bool static_data; //如果为真，表示该数据是静态的，并非来自Storage，不需要被释放
    bool delay_alloc; //数据分配是否需要延缓，注意对辅助数据aux data无效
    NDArrayStorageType storage_type = kDefaultStorage;
    std::vector<int> aux_types;
    Context ctx;
    TShape storage_shape;
    std::vector<TShape> aux_shapes;
};
```

`NDarray -->  Chunk  --> Storage` 这样一种层次关系，对 mxnet 中的数据存储进行了层层抽象，最终实现了高效的数据存储机制。

关于 ndarray 必然涉及到大量的数学运算功能，基本的矩阵加减法，矩阵向量的相乘，求最大值最小值，等等，这些功能都通过 mshadow 这个第三方模块来完成。mshadow 是一个使用 C++ 编写的矩阵运算库，它能同时支持 CPU 和 GPU。

#### 4.2.7 kvstore

KVStore，用于存储深度学习模型中的参数，以便在分布式的计算中，在多个设备/机器之间进行数据同步。KVStore 有多种类型，用来表明 kvstore 是单机存储还是多机存储，以及存储介质是什么（CPU 或 GPU 等）。


```cpp
class KVStore {
  public:
    static KVStore *Create(const char *type = "local");
    inline const std::string& type() { return type_; }
    
    virtual void Push(...) = 0;
    virtual void Pull(...) = 0;
    virtual void PullRowSparse(...) = 0;
    
    virtual void set_updater(...);
    
    typedef std::function<void(int, const NDArray&, NDArray*)> Updater;
    typedef std::function<void(const std::string&, const NDArray&, NDArray*)> StrUpdater;
};
```

初始化 KVStore 是通过 Init 来完成，可以看到其参数是 keys 和 values，以此来完成键值对的存储。key通常是整型或者字符串，而 value 是 NDArray。

每个 kv 存储中都有一个更新器，它定义了，针对指定的 key，当新 value 来到时，如何与旧 value 进行融合。这一点非常重要，因为在深度学习模型的训练中，需要迭代式的对模型参数进行更新，而更新的方式就是通过更新器来定义。

另外 Push 方法会进行相同 key 的 value 的求和，如果注册了更新器，会调用更新器阿里更新。Pull 方法主要的工作是将存储 key 对应的 value 复制到对应的输出中。

#### 4.2.8 resource

在 mxnet 中，计算中用到的一切，除 ndarray 外，都被称为资源。`ResourceManager` 这个类用于资源的管理。

```c++
class ResourceManager {
 public:
  // 获取资源
  virtual Resource Request(Context ctx, const ResourceRequest &req) = 0;
  // 设置随机数种子
  virtual void SeedRandom(uint32_t seed) = 0;
};
```

主要接口是 `Request` 方法，它的参数是一个 `ResourceRequest` 类，用来描述要获取的资源的类型，可选的类型通过如下枚举定义：

```c++
struct ResourceRequest {
  enum Type {
    kRandom, //CPU版本随机数生成器
    kTempSpace, //动态随机内存
    kParallelRandom //可以在GPU中使用的并行随机数生成器
  };
  Type type;
};
```

具体获取到的资源则封装在 `Resource` 类中。

```c++
struct Resource {
  ResourceRequest req;
  engine::VarHandle var;
  int32_t id;
  void *ptr_;
  Resource() : id(0) {}

  inline mshadow::Random<xpu, DType>* get_random(mshadow::Stream<xpu> *stream)

  inline common::random::RandGenerator<xpu, DType>* get_parallel_random() const

  inline mshadow::Tensor<xpu, ndim, real_t> get_space(
      mshadow::Shape<ndim> shape, mshadow::Stream<xpu> *stream)
      
  inline mshadow::Tensor<cpu, ndim, real_t> get_host_space(
      mshadow::Shape<ndim> shape)

  inline mshadow::Tensor<xpu, ndim, DType> get_space_typed(...)

  inline mshadow::Tensor<cpu, ndim, DType> get_host_space_typed(...)
    
  void* get_space_internal(size_t size) const;

  void *get_host_space_internal(size_t size) const;
};
```

在 Resource 类中则封装了获取随机数，和内存的方法。

资源管理模块，也采用了分层设计，顶层为 `ResourceManager` 它提供了统一且简洁的资源获取接口。`ResourceRequest` 类用来描述资源获取的具体信息。`Resource` 类是真正操作资源的类，它处理了不同平台的差异，提供了多种操作资源的方法。

牵扯到内存的获取时候，所有操作都交给了 Storage 来处理。牵扯到随机数时则交给了 mshadow 库来处理。

### 4.3 mxnet 的后端功能如何暴露给前端语言

mxnet 的后端提供了执行引擎/资源管理/多维数组/矩阵乘法/KVStore等基础设施，但这些功能不足以支撑深度学习模型的开发。mxnet 将这些基础设施通过 C API 暴露出来，使用动态链接库来完成此功能。

在 `/include/mxnet/c_api.h` 中，可以看到形如下面这样的声明：

```c++
MXNET_DLL int MXKVStoreFree(KVStoreHandle handle);
```

所有使用宏 `MXNET_DLL` 的就是 mxnet 为前端暴露的接口。其中 `MXNET_DLL` 是宏，其定义如下：

```
##ifdef _WIN32
##ifdef MXNET_EXPORTS
##define MXNET_DLL __declspec(dllexport)
##else
##define MXNET_DLL __declspec(dllimport)
##endif
##else
##define MXNET_DLL
##endif
```

这个宏抹平了 windows 和 *nix 平台的差异，将 C 接口导出的 DLL，方便其他语言调用。


### 4.4 mxnet 的 Python 接口

Python 作为深度学习从业者目前使用最为广泛的语言，自然得到 mxnet 最大的支持，实现了共 386 个类，包括了深度学习的方方面面。提供的功能具体可以概括如下：

- gluon 模块：此为 mxnet 为 Python 提供的深度学习高级接口，封装了大量基础组件，极大地降低了深度学习模型的构建难度。
- contrib 模块：此为来自 mxnet 的开源社区的贡献，包含大量实用的深度学习模块
- initializer/metric/optimizer/lr_scheduler 等模块：这些都是深度学习的基础工具，用户可能开箱即用
- ndarray: 这个模块为 python 提供了多维数组的支持，其底层通过动态链接库，调用 C 接口来完成具体操作。

#### 4.4.1 ndarray

在 mxnet 中，NDArray 是所有数学运算的核心数据结构，与 numpy 中的 ndarray 相似。与 numpy 相比，mxnet 中的 NDArray 有以下的优点：

- 对平台通用：可以使用 CPU、GPU 来运行
- 借助 mxnet Engine 可以自动并行化

在 mxnet 中 ndarray 的各种功能是通过调用 C++ 代码来实现的。

先看看 NDArray 类的部分定义：

```python

class NDArray(NDArrayBase):
    def __add__(self, other):
        return add(self, other)

    def __radd__(self, other):
        return self.__add__(other)

    def __sub__(self, other):
        return subtract(self, other)

    def take(self, *args, **kwargs):
        return op.take(self, *args, **kwargs)
    
    def sort(self, *args, **kwargs):
        return op.sort(self, *args, **kwargs)

def add(lhs, rhs):
    return _ufunc_helper(
        lhs,
        rhs,
        op.broadcast_add,
        operator.add,
        _internal._plus_scalar,
        None)


def subtract(lhs, rhs):
    return _ufunc_helper(
        lhs,
        rhs,
        op.broadcast_sub,
        operator.sub,
        _internal._minus_scalar,
        _internal._rminus_scalar)
```

可以看到在 `python/mxnet/ndarray/ndarray.py` 中并没有任何关于 ndarray 的具体实现。二元运算都通过 `_ufunc_helper` 函数，外加 `operator.x` 和 `op.x` 来完成。其他关于矩阵的操作，都通过 `op` 模来完成。

而在 `_ufunc_helper` 中，具体的运算还是交给了 `op.x`, `operator.x`, `_internal.x` 来完成。

但是在 op 模块中却是空空如也，这说明模块在运行时被修改了。这里关键代码就在 `register.py` 中：


```python
def _make_ndarray_function(handle, name, func_name):
    """Create a NDArray function from the FunctionHandle."""
    code, doc_str = _generate_ndarray_function_code(handle, name, func_name)

    local = {}
    exec(code, None, local)  # pylint: disable=exec-used
    ndarray_function = local[func_name]
    ndarray_function.__name__ = func_name
    ndarray_function.__doc__ = doc_str
    ndarray_function.__module__ = 'mxnet.ndarray'
    return ndarray_function

_init_op_module('mxnet', 'ndarray', _make_ndarray_function)
```

`_init_op_module` 这个函数位于 `base.py` 中。下面这几行代码，借助 Python 对动态链接库的支持，直接通过 C API 得到了全部在 C++ 模块中定义的关于 ndarray 的操作。

```python
check_call(_LIB.MXListAllOpNames(ctypes.byref(size),
                                 ctypes.byref(plist)))
op_names = []
for i in range(size.value):
    op_names.append(py_str(plist[i]))
    check_call(_LIB.MXListAllOpNames(ctypes.byref(size),
                                    ctypes.byref(plist)))

for name in op_names:
    hdl = OpHandle()
    check_call(_LIB.NNGetOpHandle(c_str(name), ctypes.byref(hdl)))
    #...
    function = make_op_func(hdl, name, func_name)
    
    setattr(cur_module, function.__name__, function)
    cur_module.__all__.append(function.__name__)
```

由此可以看出 Python 中 ndarray 的运行模式，即使用 Python 语言定义 Python 接口，内部通过动态链接库来调用 C 代码来实现功能。


#### 4.4.2 Gluon

Gluon是MXNet的动态图接口;Gluon学习了Keras，Chainer，和Pytorch的优点，并加以改进。接口更简单，且支持动态图（Imperative）编程。相比TF，Caffe2等静态图（Symbolic）框架更加灵活易用。同时Gluon还继承了MXNet速度快，省显存，并行效率高的优点，并支持静、动态图混用，比Pytorch更快。

**类图关系**

![](https://wangyu-name.oss-cn-hangzhou.aliyuncs.com/superbed/2019/05/29/5cee98c9451253d178227c87.jpg)

**主要类关系**

![](https://wangyu-name.oss-cn-hangzhou.aliyuncs.com/superbed/2019/05/29/5cee98f3451253d17822811b.jpg)


**设计特色分析**

gluon 通过dataloader进行数据加载，对数据集进行循环遍历。而dataloader采用迭代器模式，支持以不同的方式遍历一个聚合对象，且在同一个聚合上可以有多个遍历，同时在迭代器模式中，增加新的聚合类和迭代器类都很方便，无须修改原有代码。

但由于迭代器模式将存储数据和遍历数据的职责分离，增加新的聚合类需要对应增加新的迭代器类，类的个数成对增加，这在一定程度上增加了系统的复杂性。

gluon在构建神经网络的时候，各种算子、loss、parameter的选取采用的是策略模式，这样的好处是算法可以自由切换，避免使用多重条件判断且扩展性良好。

#### 4.4.3 data 模块

机器学习，尤其是深度学习模型训练策略基本都采用 mini-batch 梯度下降法，训练深度学习模型时，需要将全部样本分为大小相同的多个 batch，逐一送进模型进行。这牵扯到样本集的预处理，样本集的打乱与分组，batch 的抽样策略等等。

通常，人们会写一堆脚本来预处理样本，然后实现一个生成器来完成 batch 的产出，但自己实现往往导致代码可读性不佳，还容易出 bug。DataLoader 提供了一整套的解决方案，采用一种统一的数据处理模型，并在内部处理了样本的抽样/打乱等常见操作，这样开发者能够将更多精力放在深度学习模型的调试上，而非数据的预处
理上。

data 模块主要包含下面这些文件和类：

```sh
- class DataLoader(object)
    - class Dataset(object)
        - class SimpleDataset(Dataset)
        - class ArrayDataset(Dataset)
        - class RecordFileDataset(Dataset)
        - class _DownloadedDataset(Dataset)
    - class Sampler(object)
        - class SequentialSampler(Sampler)
        - class RandomSampler(Sampler)
        - class BatchSampler(Sampler)
```

这里的缩进表示依赖关系，或者类的继承。这里 `Dataset` 负责为 `DataLoader` 提供数据，`Sampler` 负责从 DataSet 中进行数据采样。

Dataloader 采用的是迭代器模式，加载Dataset，迭代时返回 batch 大小的样本。DataSet 的定义分词简单，仅仅定义了三个接口，用户需要继承 Dataset 并自己实现 `__getitem__` 和 `__len__` 接口。

```python
class Dataset(object):
    # 用 index 获取元素
    def __getitem__(self, idx):
        raise NotImplementedError
    # 返回 dataset 的长度
    def __len__(self):
        raise NotImplementedError
    # 返回新的 dataset，新的 dataset 中使用 fn 对各个元素进行处理
    def transform(self, fn, lazy=True):
        trans = _LazyTransformDataset(self, fn)
        if lazy:
            return trans
        return SimpleDataset([i for i in trans])
```

Sampler 类的接口也很简单，仅仅需要实现一个迭代器，返回一组下标即可，这里以 `RandomSampler` 为例子：

```python
class RandomSampler(Sampler):
    def __init__(self, length):
        self._length = length

    def __iter__(self):
        indices = np.arange(self._length)
        np.random.shuffle(indices)
        return iter(indices)

    def __len__(self):
        return self._length
```

DataLoader 通过 Sampler 得到下标，然后利用该下标去 Dataset 中拿数据，DataLoader 将这些数据包装为 batch，使用迭代器返回。直接在 dataloader 上进行迭代就可以得到批量的数据，用来训练模型。

```python
for x, y in dataloader:
    loss = model(x, y)
```

DataLoader 的设计分离了数据预处理，数据获取，使用 DataSet 和 Sampler 两个类来分别负责数据处理和数据采样，DataLoader 只关注数据的组装，分工明确，实现了高度的可定制化，同时保证了易用性。



#### 4.4.4 nn 模块

实现了很多神经网络基本组件：全连接层、各种卷积层、各种激活函数、各种 Pooling 层、以及 Embedding, Dropout，BatchNorm 等常用部件。

这些大多继承了 Block 类，Block 类定义对神经网络的计算进行了抽象。基于神经网络分层的理念，Block 定义了 forward 方法。数据在神经网络中按层流动，forward 方法在数据从一层过度到下一层时对数据做一次处理。这是一种 pipeline 的模式。

```python
from mxnet.gluon import Block, nn
from mxnet import ndarray as F

class Model(Block):
    def __init__(self, **kwargs):
        super(Model, self).__init__(**kwargs)
        # use name_scope to give child Blocks appropriate names.
        with self.name_scope():
            self.dense0 = nn.Dense(20)
            self.dense1 = nn.Dense(20)

    def forward(self, x):
        x = F.relu(self.dense0(x))
        return F.relu(self.dense1(x))

model = Model()
model.initialize(ctx=mx.cpu(0))
model(F.zeros((10, 10), ctx=mx.cpu(0)))
```

如何继承了 Block 的类只需要关注 forward 方法的实现，用户可以根据自己的需要在 forward 中定义数据处理方法。

nn 模块中的其他类就是根据深度学习算法实现了各自的 forward 方法。在 Block 中实现了类的 `__call__` 方法，因此每一个基础自 Block 的类的实例都可以像函数那样调用。这进一步对 Block 进行了抽象，因为像 `Conv2D` `MaxPool2D` 等此类 Block 的子类实际上就是一种运算。将其视为函数，可以极大地提高代码的可读性。

```python
def __call__(self, *args):
    for hook in self._forward_pre_hooks.values():
        hook(self, args)

    out = self.forward(*args)

    for hook in self._forward_hooks.values():
        hook(self, args, out)

    return out
```


在 Block 的基础上， mxnet 还定义了 HybridBlock 类，它继承自 Block 类，HybridBlock 同时支持符号式编程和命令式编程，HybridBlock 类可以调用 `hybridize()` 方法，从命令式变为符号式，将动态图转化为静态图，以提高模型的计算性能和移植性。HybridBlock 有如下特点：


- 所有的子块，即在 HybridBlock 的 forward 中调用的其他 Block 都需要是 HybridBlock。
- 所有的 forward 只能使用 NDarray 和 Symbol 实现
- forward 中的流程不能改变，即不能有条件语句

这三个要求和很容易理解，因为只有满足这几个条件，静态图才能构建的起来。


#### 4.4.5 loss 模块

在机器学习中，包含很多计算 Loss 的方法，比如 MSE，CrossEntropy 等。loss 的计算就是目标值和目的值之间的一个数学运算，按理说一个函数接收两个参数就可以搞定了。但有的时候，一个 Loss 可以有其他的配置项，比如在多分类任务时常常采用 CrossEntropy 作为 loss，但是常常任务会给不同类别以不同的权重，这就需要进行配置。

在 mxnet 中将很多不同 Loss Function 实现成了类，而这些类归根结底还是继承了 HybridBlock 类。因为 Loss Function 中的运算流程不会变。

目前实现的 Loss 有如下这些：

```python
class Loss(HybridBlock) # 计算`label`和`pred`之间的均方误差。
class L2Loss(Loss)
class L1Loss(Loss)
class SigmoidBinaryCrossEntropyLoss(Loss) # 二元分类的交叉熵损失。
class SoftmaxCrossEntropyLoss(Loss) # 计算softmax交叉熵损失。
class KLDivLoss(Loss) # Kullback-Leibler分歧损失。
class CTCLoss(Loss)
class HuberLoss(Loss)
class HingeLoss(Loss)
class SquaredHingeLoss(Loss)
class LogisticLoss(Loss)
class TripletLoss(Loss)
class PoissonNLLLoss(Loss)
class CosineEmbeddingLoss(Loss)
```


#### 4.4.6 model zoo

这里包含了一些在业界广泛使用的网络结构，方便用户利用。

```
- alexnet ：AlexNet 模型
- densenet： DenseNet 模型
- inception： Inception3 模型。
- mobilenet： mobilenet 模型。
- resnet： resnet模型。
- squeezenet： squeezenet模型。
```

Model_zoo、nn、rnn、loss采用的是策略模式，把针对一个算法标识的一系列具体算法分别封装在不同的类中，他的优点是上下文和具体策略是松耦合关系。




#### 4.4.7 Metric

在模型的训练过程中需要时刻关注模型的精度、误差等参数，以此来判断模型是否收敛或是否过拟合等。对于不同的任务，精度或误差的计算方式也不同。mxnet 提供了大量的 Metric 类，方便用户追踪模型的各项指标。

它的用法非常简单，这里以 Accuracy 为例：

```python
acc = mx.metric.Accuracy()
acc.update(preds = predicts, labels = labels)
print(acc.get())
```

即在训练过程中不断地使用 `update` 来更新，并通过 `get` 方法来得到实时的精度。为了实现此功能，`Metric` 类提供了如下主要接口：

```python
def update(self, labels, preds)
def reset(self)
def get(self)
```

Metric 类有如下一些子类：

```python
- class EvalMetric(object)
    - class CompositeEvalMetric(EvalMetric)
    - class Accuracy(EvalMetric)
    - class TopKAccuracy(EvalMetric)
    - class _BinaryClassificationMetrics(object)
    - class F1(EvalMetric)
    - class MCC(EvalMetric)
    - class Perplexity(EvalMetric)
    - class MAE(EvalMetric)
    - class MSE(EvalMetric)
    - class RMSE(EvalMetric)
    - class CrossEntropy(EvalMetric)
    - class NegativeLogLikelihood(EvalMetric)
    - class PearsonCorrelation(EvalMetric)
    - class PCC(EvalMetric)
    - class Loss(EvalMetric)
    - class CustomMetric(EvalMetric)
```

#### 4.4.8 initializer

实验表明神经网络模型的参数初始化策略，对模型的训练速度、最终表现有极大的影响。mxnet 定义了多种参数初始化策略, `Initializer` 和其子类定义了大量的参数初始化策略。

```python
- class Initializer(object)
    - class Zero(Initializer)
    - class One(Initializer)
    - class Constant(Initializer)
    - class Uniform(Initializer)
    - class Normal(Initializer)
    - class Orthogonal(Initializer)
    - class Xavier(Initializer)
        - class MSRAPrelu(Xavier)
    - class Bilinear(Initializer)
    - class LSTMBias(Initializer)
    - class FusedRNN(Initializer)
```

需要进行初始化的参数都是 `Parameter` 类的实例，这样让 `Initializer` 和 `Parameter` 有了紧密的联系。Initializer 作为参数传递给继承自 Block 的神经网络基础构件。而后交给 Parameter 以在合适的时间对其参数进行初始化。

```python
self.weight = self.params.get('weight', shape=(units, in_units),
     init=weight_initializer, dtype=dtype,
     allow_deferred_init=True)
```

#### 4.4.9 Optimizer

采用固定学习速率的训练方式是低效的，学术界提出了很多行之有效的优化策略，这些优化器能够对待更新的参数做一些更优化的改变，使得训练过程更加快速。

mxnet 提供了一下优化器。

| 优化器     | 描述 |
|:----------|:----|
| Optimizer | The base class inherited by all optimizers. |
| SGD | The SGD optimizer with momentum and weight decay. |
| NAG | Nesterov accelerated SGD. |
| RMSProp | The RMSProp optimizer. |
| Adam | The Adam optimizer. |
| AdaGrad | AdaGrad optimizer. |
| AdaDelta | The AdaDelta optimizer. |
| Adamax | The AdaMax optimizer. |
| Nadam | The Nesterov Adam optimizer. |
| DCASGD | The DCASGD optimizer. |
| SGLD | Stochastic Gradient Riemannian Langevin Dynamics. |
| Signum | The Signum optimizer that takes the sign of gradient or momentum. |
| FTML | The FTML optimizer. |
| LBSGD | The Large Batch SGD optimizer with momentum and weight decay. |
| Ftrl | The Ftrl optimizer. |

它的使用方法如下：

```python
lr_sch = mx.lr_scheduler.FactorScheduler(step=100, factor=0.9)
sgd = SGD(learning_rate=0.1, lr_scheduler=lr_sch)
mod.init_optimizer(optimizer=sgd)
```

LRScheduler 实现了当下深度学习领域广泛使用的 learning rate 调整策略，在 mxnet 中也有一些实现。

```python
- class LRScheduler(object)
    - class FactorScheduler(LRScheduler)
    - class MultiFactorScheduler(LRScheduler)
    - class PolyScheduler(LRScheduler)
    - class CosineScheduler(LRScheduler)
```


## 5. 设计特色分析

### 5.1 优点

#### 5.1.1 多语言支持

mxnet 与同类竞品，如 TensorFlow、PyTorch，比起来其特色就是支持多平台，多语言，而 TensorFlow 和 PyTorch 支持的语言则很有限，比如 TensorFlow 支持 C++/Python/JavaScript 和 PyTorch 仅支持 Python。这得益于其前后端分离的设计理念，通过 C API 能够很好地粘合前后端，使得多语言支持变得容易了许多。

#### 5.1.2 内存消耗与性能

mxnet 中使用的多维数组接口为 ndarray ，它类似于 `numpy.ndarray` 和 `torch.tensor`，其优势在于通过背后的 Engine，对依赖关系进行了分析，并使用对线程加大并行程度，这样 mxnet 在性能上优于 PyTorch 核 TensorFlow。

![](https://wangyu-name.oss-cn-hangzhou.aliyuncs.com/superbed/2019/05/30/5cefced3451253d1783b4ef2.jpg)

图来自 [[4]](https://www.cs.cmu.edu/~muli/file/mxnet-learning-sys.pdf)


#### 5.1.3 高级 API - Gluon

2017 年 mxnet 借鉴 PyTorch 推出了 Gluon 接口，Gluon 之于 mxnet 就相当于 Keras 之于 TensorFlow。这让 mxnet 的易用性大幅提高。Gluon 对深度学习项目开发过程中可能用的的工具、以及深度学习算法中的概念进行了高度的抽象，提供了大量开箱即用的深度学习算法模块，让 mxnet 的上手难度大幅降低。也提高了 mxnet 的易用性。这一点上，可以想象一个新手使用 TensorFlow 1.X 版本的感受，以及使用 Keras 的感受。

Gluon 采用 Keras 和 Numpy 风格 API，Layer 可以自动判断输入长度。而 Pytorch 则每一层都要记住前一层输出长度的麻烦，从卷积层到全联接层过度时需要手动计算长度。在 Gluon 每层只要指定输出长度，输入长度则可以由系统自动计算。


### 5.2 可改进的点

#### 5.2.1 完善功能

mxnet 一直宣扬宣扬多语言支持，但 mxnet 的开发团队本就不大，核心成员将较少的精力分散到对其他语言的支持上去了，反而导致看起来支持的语言很多，但是各种语言的支持都不是最优。而 TensorFlow 的开发者很多，而且将集中精力于对 C++ 和 Python，这样在 C++ 和 Python 方面，TensorFlow 自然能做的更好。mxnet 的 C++ 接口的实现严重缺少基础设施，用户需要的是清晰的文档和完善的功能。所以 mxnet 应该集中精力于 Python/C++ 等深度学习流行语言，将对这些语言的支持做好。


#### 5.2.2 完善文档

mxnet 的开发前期主要由社区驱动，核心开发人员都是兼职，这导致文档写的比较粗糙，而且存在代码中的具体实现和文档描述不一致，这因为更新了代码但文档却没有同步更新。TensorFlow 和 PyTorch 都有专门的开发团队，用户广泛，社区活跃，因此在文档方面 mxnet 还远远落后。


## 6. 参考文献

1\. [mxnet architecture](https://mxnet.incubator.apache.org/versions/master/architecture/index.html)<br>
2\. [mxnet Python API](https://mxnet.incubator.apache.org/versions/master/api/python/index.html)<br>
3\. [Dive into Deep Learning](https://d2l.ai/chapter_introduction/intro.html)<br>
4\. [MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems](https://www.cs.cmu.edu/~muli/file/mxnet-learning-sys.pdf)<br>
5\. [mxnet Documentation](http://mxnet.incubator.apache.org/doxygen/annotated.html)<br>
6\. [mxnet wiki](https://cwiki.apache.org/confluence/display/MXNET/MXNet+Runtime)<br>
7\. [MXNet Overview](https://raw.githubusercontent.com/cyrusmvahid/GluonBootcamp/master/slides/MXNet%20Overview.pptx)<br>